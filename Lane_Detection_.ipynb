{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDOThPscGoXE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def region_of_interest(img, vertices):\n",
        "    mask = np.zeros_like(img)\n",
        "    cv2.fillPoly(mask, vertices, 255)\n",
        "    masked_img = cv2.bitwise_and(img, mask)\n",
        "    return masked_img\n",
        "\n",
        "def draw_lines(img, lines, color=(0, 0, 255), thickness=3):\n",
        "    for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open a video capture object\n",
        "cap = cv2.VideoCapture('your_video.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to grayscale\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise and improve edge detection\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Perform Canny edge detection\n",
        "    edges = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
        "\n",
        "    # Define the region of interest vertices\n",
        "    height, width = edges.shape\n",
        "    roi_vertices = [(0, height), (width / 2, height / 2), (width, height)]\n",
        "    masked_edges = region_of_interest(edges, np.array([roi_vertices], np.int32))\n",
        "\n",
        "    # Perform Hough line transformation to detect lines in the image\n",
        "    lines = cv2.HoughLinesP(\n",
        "        masked_edges, rho=1, theta=np.pi/180, threshold=50, minLineLength=100, maxLineGap=50\n",
        "    )\n",
        "\n",
        "    # Create a blank image to draw the detected lanes on\n",
        "    line_img = np.zeros_like(frame)\n",
        "\n",
        "    draw_lines(line_img, lines)\n",
        "\n",
        "    # Overlay the detected lanes on the original frame\n",
        "    combined_img = cv2.addWeighted(frame, 0.8, line_img, 1, 0)\n",
        "\n",
        "    cv2.imshow(\"Lane Detection\", combined_img)\n",
        "\n",
        "    # Exit loop when 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the capture object and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "V6jkCGHZG0BS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}